{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#to suppress all tensorflow warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from os import environ, chdir\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import matplotlib \n",
    "import numpy \n",
    "import piexif\n",
    "import keras\n",
    "import os \n",
    "import random\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "#Model Building Libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Dropout, Flatten, Dense \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)75:25 Training and Test ratio is used as it yielded best Testing accuracy\n",
    "2)Since Data Augmentation yields better results we are only using Data Augmented Images \n",
    "3)10 Epochs for Training  \n",
    "4)Train and Test are already loaded with 75:25 ratio images.so we are not redoing the images split and directly accessing the train and test folder respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training fresh images 1566\n",
      "Number of training rotten images 2207\n",
      "Number of Training images  3773\n",
      "********************************************************************\n",
      "Number of testing fresh images 522\n",
      "Number of testing rotten images 736\n",
      "Number of Testing images  1258\n"
     ]
    }
   ],
   "source": [
    "#Split ratio \n",
    "train_size = 0.75\n",
    "\n",
    "_,_, fresh_images = next(os.walk('C:/Users/Deepika/CS5000/Model_Transfer_Learning/Dataset/AppleImages/fresh'))\n",
    "_,_, rotten_images = next(os.walk('C:/Users/Deepika/CS5000/Model_Transfer_Learning/Dataset/AppleImages/rotten'))\n",
    "\n",
    "#Total number of fresh and rotten images\n",
    "num_fresh_images = len(fresh_images)\n",
    "num_rotten_images = len(rotten_images)\n",
    "\n",
    "#Split fresh images into training images and test images with given split ratio\n",
    "num_fresh_images_train = int(train_size * num_fresh_images)\n",
    "num_fresh_images_test = num_fresh_images - num_fresh_images_train\n",
    "\n",
    "#Split rotten images into training images and test images with given split ratio\n",
    "num_rotten_images_train = int(train_size * num_rotten_images)\n",
    "num_rotten_images_test = num_rotten_images - num_rotten_images_train\n",
    "\n",
    "print(\"Number of training fresh images\",num_fresh_images_train)\n",
    "print(\"Number of training rotten images\",num_rotten_images_train)\n",
    "print(\"Number of Training images \",num_fresh_images_train+num_rotten_images_train)\n",
    "print(\"********************************************************************\")\n",
    "print(\"Number of testing fresh images\",num_fresh_images_test)\n",
    "print(\"Number of testing rotten images\",num_rotten_images_test)\n",
    "print(\"Number of Testing images \",num_fresh_images_test+num_rotten_images_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step size is 118,Testing step size 39\n"
     ]
    }
   ],
   "source": [
    "#Basic hyperparameters or the original Hyperparameters\n",
    "FILTER_SIZE = 3 #best size -same as before\n",
    "NUM_FILTERS = 32 #best count -same as beore\n",
    "INPUT_SIZE  = 64\n",
    "MAXPOOL_SIZE = 3  \n",
    "BATCH_SIZE = 32 #best batch size found\n",
    "EPOCHS = 10 \n",
    "\n",
    "\n",
    "#Steps per epoch is based on Training so in total we have 1670 fresh and 2354 rotten images =4024/batch size=125.75 =>126\n",
    "STEP_PER_TRAIN = round((num_rotten_images_train+num_fresh_images_train)/BATCH_SIZE)\n",
    "STEP_PER_TEST= round((num_rotten_images_test+num_fresh_images_test)/BATCH_SIZE)\n",
    "\n",
    "print(\"Training step size is {0},Testing step size {1}\".format(STEP_PER_TRAIN,STEP_PER_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3773 images belonging to 2 classes.\n",
      "Found 1258 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Generator with Data Augmentation\n",
    "training_data_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                                             shear_range = 0.2,\n",
    "                                             zoom_range = 0.2,\n",
    "                                             horizontal_flip = True)#AUGMENTATION DONE HERE SINCE THIS IS TRAINING IMAGE\n",
    "\n",
    "training_set = training_data_generator.flow_from_directory('C:/Users/Deepika/CS5000/Model_Transfer_Learning/Dataset/AppleImages/Train/',\n",
    "                                                           target_size=(INPUT_SIZE,INPUT_SIZE),                                                    \n",
    "                                                           batch_size=BATCH_SIZE,                                                    \n",
    "                                                           class_mode='binary')\n",
    "\n",
    "testing_data_generator = ImageDataGenerator(rescale = 1./255)#NO MUCH AUGMENTATION DONE HERE-NO CHANGE\n",
    "\n",
    "test_set = testing_data_generator.flow_from_directory('C:/Users/Deepika/CS5000/Model_Transfer_Learning/Dataset/AppleImages/Test/',                               \n",
    "                                                      target_size=(INPUT_SIZE,INPUT_SIZE),                        \n",
    "                                                      batch_size=BATCH_SIZE,                                   \n",
    "                                                      class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 157,857\n",
      "Trainable params: 157,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 60s 509ms/step - loss: 0.4404 - acc: 0.7920\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 39s 329ms/step - loss: 0.2265 - acc: 0.9062\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 38s 320ms/step - loss: 0.1833 - acc: 0.9296\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 38s 318ms/step - loss: 0.1666 - acc: 0.9364\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 38s 319ms/step - loss: 0.1437 - acc: 0.9451\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 38s 319ms/step - loss: 0.1249 - acc: 0.9510\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 38s 319ms/step - loss: 0.1279 - acc: 0.9523\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 38s 320ms/step - loss: 0.0977 - acc: 0.9637\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 38s 320ms/step - loss: 0.1169 - acc: 0.9512\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 37s 318ms/step - loss: 0.0953 - acc: 0.9637\n",
      "Loss :0.06153457330014461 and Accuracy: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "#Remove TF warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#Model4 (conv+relu+maxpool)(conv+relu+maxpool)(Dense 128)(Dense 1)\n",
    "classifier_adam = Sequential() \n",
    "\n",
    "classifier_adam.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),  \n",
    "                 input_shape = (INPUT_SIZE, INPUT_SIZE, 3),                \n",
    "                 activation = 'relu')) \n",
    "\n",
    "#we add a max pooling layer:\n",
    "classifier_adam.add(MaxPooling2D(pool_size = (MAXPOOL_SIZE, MAXPOOL_SIZE))) \n",
    "\n",
    "#Repeat 2nd convolutional layer\n",
    "classifier_adam.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),  \n",
    "                 input_shape = (INPUT_SIZE, INPUT_SIZE, 3),                \n",
    "                 activation = 'relu')) \n",
    "\n",
    "#we add a max pooling layer:\n",
    "classifier_adam.add(MaxPooling2D(pool_size = (MAXPOOL_SIZE, MAXPOOL_SIZE))) \n",
    "\n",
    "#flatten multi dimensional array to single to 1dimensional vector\n",
    "classifier_adam.add(Flatten())\n",
    "\n",
    "#add a fully connected layer with 128 nodes:\n",
    "classifier_adam.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "#one last fully connected layer to our Model:\n",
    "classifier_adam.add(Dense(units = 1, activation = 'sigmoid')) \n",
    "\n",
    "classifier_adam.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "classifier_adam.summary()\n",
    "\n",
    "#Fit model for epochs=10 \n",
    "history_adam=classifier_adam.fit_generator(training_set, \n",
    "                    steps_per_epoch = STEP_PER_TRAIN,\n",
    "                    epochs=EPOCHS \n",
    "                    )\n",
    "\n",
    "#Evaluate model using Validation set\n",
    "loss,acc=classifier_adam.evaluate_generator(generator=test_set,steps=STEP_PER_TEST)\n",
    "print(\"Loss :{0} and Accuracy: {1}\".format(loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataset for 0.75 dataset\n",
    "#maxpool size 3\n",
    "classifier_adam.save('Fruit_status_final_model_0.75_97.92.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 157,857\n",
      "Trainable params: 157,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_adam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_adam.save(\"Fruit_Status_97_92.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
